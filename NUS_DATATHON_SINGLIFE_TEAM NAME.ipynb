{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .parquet file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "filepath = \"./data/catB_train.parquet\" \n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clntnum                      object\n",
       "race_desc                    object\n",
       "ctrycode_desc                object\n",
       "clttype                      object\n",
       "stat_flag                    object\n",
       "                             ...   \n",
       "flg_gi_claim_29d435_ever     object\n",
       "flg_gi_claim_058815_ever     object\n",
       "flg_gi_claim_42e115_ever     object\n",
       "flg_gi_claim_856320_ever     object\n",
       "f_purchase_lh               float64\n",
       "Length: 304, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('datathon.parquet')\n",
    "\n",
    "# Convert target col to 0 or 1 (binary)\n",
    "df[\"f_purchase_lh\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. General Client Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race_desc        0\n",
       "ctrycode_desc    0\n",
       "cltsex_fix       0\n",
       "stat_flag        0\n",
       "clttype          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputing missing values for client information\n",
    "clnt_info_columns = ['race_desc', 'ctrycode_desc', 'cltsex_fix', 'clntnum', 'clttype', 'stat_flag', 'min_occ_date', 'cltdob_fix']\n",
    "\n",
    "for clnt_info_column in clnt_info_columns:\n",
    "    df[clnt_info_column] = df[clnt_info_column].fillna(df[clnt_info_column].mode()[0])\n",
    "\n",
    "df[['race_desc', 'ctrycode_desc', 'cltsex_fix', 'stat_flag', 'clttype']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Client Risk and Status Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flg_substandard               0\n",
       "flg_is_borderline_standard    0\n",
       "flg_is_revised_term           0\n",
       "flg_is_rental_flat            0\n",
       "flg_has_health_claim          0\n",
       "flg_has_life_claim            0\n",
       "flg_gi_claim                  0\n",
       "flg_is_proposal               0\n",
       "flg_with_preauthorisation     0\n",
       "flg_is_returned_mail          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputing missing client risk and status indicator\n",
    "clnt_risk_status_columns = ['flg_substandard', 'flg_is_borderline_standard', 'flg_is_revised_term', 'flg_is_rental_flat', 'flg_has_health_claim', 'flg_has_life_claim', 'flg_gi_claim', 'flg_is_proposal', 'flg_with_preauthorisation', 'flg_is_returned_mail']\n",
    "\n",
    "for clnt_risk_status_column in clnt_risk_status_columns:\n",
    "    df[clnt_risk_status_column] = df[clnt_risk_status_column].fillna(df[clnt_risk_status_column].mode()[0])\n",
    "\n",
    "df[['flg_substandard', 'flg_is_borderline_standard', 'flg_is_revised_term', 'flg_is_rental_flat', 'flg_has_health_claim', 'flg_has_life_claim', 'flg_gi_claim', 'flg_is_proposal', 'flg_with_preauthorisation', 'flg_is_returned_mail']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Client Consent and Communication Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_consent_to_mail     0\n",
       "is_consent_to_email    0\n",
       "is_consent_to_call     0\n",
       "is_consent_to_sms      0\n",
       "is_valid_dm            0\n",
       "is_valid_email         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputing missing client consent and communication preferences\n",
    "clnt_consent_columns = ['is_consent_to_mail', 'is_consent_to_email', 'is_consent_to_call', 'is_consent_to_sms', 'is_valid_dm', 'is_valid_email']\n",
    "\n",
    "for clnt_consent_column in clnt_consent_columns:\n",
    "    df[clnt_consent_column] = df[clnt_consent_column].fillna(df[clnt_consent_column].mode()[0])\n",
    "\n",
    "df[['is_consent_to_mail', 'is_consent_to_email', 'is_consent_to_call', 'is_consent_to_sms', 'is_valid_dm', 'is_valid_email']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Policy and Claim History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flg_latest_being_lapse, flg_latest_being_cancel, tot_inforce_pols do not have missing values\n",
    "empty_val_check = df[['flg_latest_being_lapse','flg_latest_being_cancel','tot_inforce_pols']]\n",
    "empty_val_check.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing negative values for n_months_last_bought_products, no missing values\n",
    "median_without_negatives = df['n_months_last_bought_products'][df['n_months_last_bought_products'] >= 0].median()\n",
    "\n",
    "df['n_months_last_bought_products'] = df['n_months_last_bought_products'].apply(lambda x: x if x >= 0 else median_without_negatives)\n",
    "\n",
    "#imputing recency_lapse with 9999 if flg_latest_being_lapse == 0, otherwise median \n",
    "df.loc[df['flg_latest_being_lapse'] == 0, 'recency_lapse'] = 9999\n",
    "df.loc[(df['flg_latest_being_lapse'] == 1) & (df['recency_lapse'].isna()), 'recency_lapse'] = 0\n",
    "df['flg_latest_being_lapse'].isna().sum()\n",
    "\n",
    "#doing the same for cancellations\n",
    "df.loc[df['flg_latest_being_cancel'] == 0, 'recency_cancel'] = 9999\n",
    "df.loc[(df['flg_latest_being_cancel'] == 1) & (df['recency_cancel'].isna()), 'recency_cancel'] = 0\n",
    "df['flg_latest_being_cancel'].isna().sum()\n",
    "\n",
    "#tot_inforce_pols has no missing values\n",
    "\n",
    "#imputing missing values of tot_cancel_pols\n",
    "df.loc[df['flg_latest_being_cancel'] == 0, 'tot_cancel_pols'] = 0\n",
    "df.loc[(df['tot_cancel_pols'].isna()) & (df['flg_latest_being_cancel'] == 1), 'tot_cancel_pols'] = 1\n",
    "\n",
    "#imputing missing values of f_ever_declined_la\n",
    "df['f_ever_declined_la'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Demographic and Household Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data type of the column to the correct data type\n",
    "df['hh_size_est'].replace('>4', 5, inplace=True)\n",
    "\n",
    "income_mapping = {\n",
    "    'A.ABOVE200K': 200001,  \n",
    "    'B.100K-200K': 150000,  \n",
    "    'C.60K-100K': 80000,\n",
    "    'D.30K-60K': 45000,\n",
    "    'E.BELOW30K': 15000\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'annual_income' column\n",
    "df['annual_income_est'].replace(income_mapping, inplace=True)\n",
    "\n",
    "# Fill in missing values with the median \n",
    "col_names_fill_median = ['hh_20', 'pop_20', 'hh_size', 'hh_size_est', 'annual_income_est']\n",
    "\n",
    "for c in col_names_fill_median:\n",
    "    median_value = df[c].median()\n",
    "    df[c].fillna(median_value, inplace=True)\n",
    "\n",
    "# Fill in missing values with the mode \n",
    "col_names_fill_mode = ['is_housewife_retiree', 'is_sg_pr', 'is_class_1_2', 'is_dependent_in_at_least_1_policy']\n",
    "\n",
    "for c in col_names_fill_mode:\n",
    "    mode_value = df[c].mode()[0]\n",
    "    df[c].fillna(mode_value, inplace=True)\n",
    "\n",
    "# Fill in missing values with 0\n",
    "col_names_fill_zero = ['flg_affconnect_show_interest_ever', 'flg_affconnect_ready_to_buy_ever', 'flg_affconnect_lapse_ever', 'affcon_visit_days', 'clmcon_visit_days']\n",
    "for c in col_names_fill_zero:\n",
    "    df[c].fillna(0, inplace=True)\n",
    "\n",
    "# Fill in missing values with 9999\n",
    "col_names_fill_9999 = ['n_months_since_visit_affcon', 'recency_clmcon', 'recency_clmcon_regis']\n",
    "for c in col_names_fill_9999:\n",
    "    df[c].fillna(9999, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated 'clntnum' values: 0\n"
     ]
    }
   ],
   "source": [
    "duplicated_clntnum_count = df['clntnum'].duplicated(keep=False).sum()\n",
    "print(f\"Number of duplicated 'clntnum' values: {duplicated_clntnum_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Purchase and Lapse Metrics for Specific Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629600"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of empty values in lapse data\n",
    "lapse_specific = df.loc[:, 'lapse_ape_ltc_1280bf':'n_months_since_lapse_32c74c']\n",
    "lapse_specific.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in missing values with 0 for lapses\n",
    "for column in df.loc[:, 'lapse_ape_ltc_1280bf':'lapse_ape_32c74c']:\n",
    "    df[column] = df[column].fillna(0)\n",
    "\n",
    "# Fill in missing values with 9999 for n_months_since_lapse\n",
    "for column in df.loc[:, 'n_months_since_lapse_ltc_1280bf':'n_months_since_lapse_32c74c']:\n",
    "    df[column] = df[column].fillna(9999)\n",
    "\n",
    "df['n_months_since_lapse_ltc_1280bf'][13337] # checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of empty values in purchase data\n",
    "purchase_specific = df.loc[:, 'f_ever_bought_839f8a':'n_months_last_bought_32c74c']\n",
    "purchase_specific.isna().sum().sum() # 0 -> no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "    result = [] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This cell should output a list of predictions.\n",
    "test_df = pd.read_parquet(filepath)\n",
    "test_df = test_df.drop(columns=[\"f_purchase_lh\"])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
